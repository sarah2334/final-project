{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3939a88",
   "metadata": {},
   "source": [
    "***Import Libraries***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da46c91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saraq\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "import uuid\n",
    "import whisper\n",
    "import yt_dlp\n",
    "import openai\n",
    "from langchain.schema import Document\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import initialize_agent, Tool, AgentType\n",
    "from langsmith import traceable  # ‚úÖ LangSmith tracing\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from pydub import AudioSegment\n",
    "from langchain.callbacks import tracing_v2_enabled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f283fe",
   "metadata": {},
   "source": [
    "***Lang Chain Environment Setup***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bfdce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\", \"YouTube-Assistant-Project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436427b5",
   "metadata": {},
   "source": [
    "***Video-to-Text Document Pipeline***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2b57af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@traceable(name=\"Download Audio From Youtube\")\n",
    "\n",
    "\n",
    "def download_audio_from_youtube(youtube_url, output_dir=\"downloads\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_template = os.path.join(output_dir, f\"{uuid.uuid4()}.%(ext)s\")\n",
    "\n",
    "\n",
    "\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'outtmpl': output_template,\n",
    "        'quiet': True,\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "            'preferredquality': '8',\n",
    "        }],\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info_dict = ydl.extract_info(youtube_url, download=True)\n",
    "        audio_path = ydl.prepare_filename(info_dict).replace(\".webm\", \".mp3\").replace(\".mp4\", \".mp3\")\n",
    "    return audio_path\n",
    "\n",
    "\n",
    "def split_audio(audio_path: str, chunk_length_sec: int = 30):\n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "    chunk_length_ms = chunk_length_sec * 1000\n",
    "    chunk_paths = []\n",
    "\n",
    "    for i, start_ms in enumerate(range(0, len(audio), chunk_length_ms)):\n",
    "        chunk = audio[start_ms : start_ms + chunk_length_ms]\n",
    "        chunk_path = audio_path.replace(\".mp3\", f\"_chunk{i}.mp3\")\n",
    "        chunk.export(chunk_path, format=\"mp3\")\n",
    "        chunk_paths.append(chunk_path)\n",
    "\n",
    "    return chunk_paths\n",
    "\n",
    "def transcribe_with_whisper(audio_path, model_size=\"base\", chunk_length_sec=30):\n",
    "    model = whisper.load_model(model_size)\n",
    "    texts = []\n",
    "\n",
    "    chunks = split_audio(audio_path, chunk_length_sec=chunk_length_sec)\n",
    "\n",
    "    for chunk_path in chunks:\n",
    "        result = model.transcribe(chunk_path)\n",
    "        texts.append(result[\"text\"])\n",
    "        os.remove(chunk_path) \n",
    "\n",
    "    return \"\\n\\n\".join(texts)\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def convert_to_documents(texts):\n",
    "    full_text = \"\\n\\n\".join(texts)\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=100)\n",
    "    chunks = splitter.split_text(full_text)\n",
    "\n",
    "    return [Document(page_content=chunk, metadata={\"source\": \"video\"}) for chunk in chunks]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623e7d69",
   "metadata": {},
   "source": [
    "***Text Summarization***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d3f65a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "@traceable(name=\"Summarize Text\")\n",
    "def summarize_text(text):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\", \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that summarizes text.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Please summarize the following text:\\n\\n{text}\"}\n",
    "        ],\n",
    "        temperature=0.5\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f92125",
   "metadata": {},
   "source": [
    "***Vectorstore Setup & Management***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8063066",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saraq\\AppData\\Local\\Temp\\ipykernel_19288\\3641141505.py:7: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
      "C:\\Users\\saraq\\AppData\\Local\\Temp\\ipykernel_19288\\3641141505.py:9: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "import openai\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"chroma_db\",   \n",
    "    collection_name=\"search-majc\"       \n",
    ")\n",
    "\n",
    "def add_documents_to_vectorstore(docs: list[str]):\n",
    "    \"\"\"\n",
    "    docs: A list of text (strings) or Document objects\n",
    "    \"\"\"\n",
    "    documents = [\n",
    "        doc if isinstance(doc, Document) else Document(page_content=doc)\n",
    "        for doc in docs\n",
    "    ]\n",
    "    vectorstore.add_documents(documents)\n",
    "    vectorstore.persist()  \n",
    "\n",
    "def clear_vectorstore():\n",
    "        vectorstore.delete(delete_all=True) \n",
    "        vectorstore.persist() \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83660ad0",
   "metadata": {},
   "source": [
    "***RAG Chatbot Initialization***\n",
    "Q&A Bot Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66cb7f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import initialize_agent, Tool, AgentType\n",
    "import os\n",
    "\n",
    "\n",
    "@traceable(name=\"Initialize Chatbot\")\n",
    "def initialize_chatbot():\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0,\n",
    "        openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "    )\n",
    "\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_kwargs={'k': 8, 'filter': {'source': 'video'}}\n",
    "    )\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "You are an intelligent assistant that only answers based on the **transcript of a YouTube video**.\n",
    "\n",
    "Rules:\n",
    "- ONLY use information from the transcript provided.\n",
    "- DO NOT use outside knowledge, personal opinions, or make assumptions.\n",
    "- If the answer is not found in the transcript, respond clearly with:\n",
    "  \"The information is not available in the video transcript.\"\n",
    "\n",
    "Examples:\n",
    "Question: What is the main topic of the video?\n",
    "Answer: [Answer based on transcript]\n",
    "\n",
    "Question: Who is the president of the United States?\n",
    "Answer: The information is not available in the video transcript.\n",
    "\n",
    "Be brief, clear, and always stay within the content of the transcript.\n",
    "\"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        SystemMessagePromptTemplate.from_template(system_prompt),\n",
    "        HumanMessagePromptTemplate.from_template(\"Question: {question}\\n\\nContext:\\n{context}\")\n",
    "    ])\n",
    "\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        chain_type_kwargs={\"prompt\": prompt}\n",
    "    )\n",
    "\n",
    "    tools = [\n",
    "        Tool(\n",
    "            name=\"Question Answering\",\n",
    "            func=qa_chain.run,\n",
    "            description=\"Answers questions only based on the transcript of a YouTube video.\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    agent = initialize_agent(\n",
    "        tools=tools,\n",
    "        agent_type=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        llm=llm,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    return agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74250b5",
   "metadata": {},
   "source": [
    "***Chatbot Interaction / Query Execution***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93fbb26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@traceable(name=\"Chat With Bot\")\n",
    "def chat_with_bot(user_input):\n",
    "    agent = initialize_chatbot()\n",
    "    response = agent.run(user_input)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e6ef95",
   "metadata": {},
   "source": [
    "***Deployment***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e0f9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saraq\\AppData\\Local\\Temp\\ipykernel_19288\\2369273932.py:47: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot_display = gr.Chatbot(label=\"üí¨ Chat with the Bot\", height=400)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://87783c265900da6b2b.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://87783c265900da6b2b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saraq\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "C:\\Users\\saraq\\AppData\\Local\\Temp\\ipykernel_19288\\3556057780.py:14: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n",
      "C:\\Users\\saraq\\AppData\\Local\\Temp\\ipykernel_19288\\3556057780.py:62: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n",
      "C:\\Users\\saraq\\AppData\\Local\\Temp\\ipykernel_19288\\3855620171.py:4: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = agent.run(user_input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the Question Answering tool to find out the topic of the video.\n",
      "Action: Question Answering\n",
      "Action Input: Transcript of the YouTube video\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe video is about exploring the OSI model, its importance in networking, and how it is the blueprint behind emails, video streaming, and website visits. It also mentions testing OSI skills and hints at upcoming topics like IP addressing in the field of IT.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have gathered information about the topic of the video.\n",
      "Final Answer: The topic of the video is exploring the OSI model and its importance in networking.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the Question Answering tool to find the answer to this question.\n",
      "Action: Question Answering\n",
      "Action Input: \"What is a PIPA?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: A PIPA, or automatic private IP addressing, is what happens when a computer can't find a DHCP server to give it an appropriate IP address. Instead, it assigns itself a random address in the range of 169.254.x.x.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to provide this information as the final answer to the original question.\n",
      "Final Answer: A PIPA, or automatic private IP addressing, is what happens when a computer can't find a DHCP server to give it an appropriate IP address. Instead, it assigns itself a random address in the range of 169.254.x.x.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import gradio as gr   \n",
    "chat_history = []\n",
    "\n",
    "with gr.Blocks(title=\"YouTube AI Assistant\", theme=gr.themes.Soft()) as interface:\n",
    "    gr.Markdown(\"\"\"\n",
    "    <style>\n",
    "        @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+Arabic:wght@400;700&display=swap');\n",
    "        html, body, input, textarea, button, .gr-chatbot, .gr-textbox, .gr-button, .gr-accordion {\n",
    "            font-family: 'Noto Sans Arabic', sans-serif !important;\n",
    "        }\n",
    "    </style>\n",
    "    <div style=\"text-align: center;\">\n",
    "        <h1 style=\"color:#3b82f6;\">üé• YouTube AI Assistant</h1>\n",
    "        <p style=\"font-size: 16px;\">Transcribe, Summarize, and Ask Questions About Any YouTube Video</p>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "\n",
    "    with gr.Tabs():\n",
    "        with gr.TabItem(\"üìº Transcribe & Summarize\"):\n",
    "            with gr.Column():\n",
    "                youtube_url = gr.Textbox(label=\"üîó YouTube URL\", placeholder=\"Paste YouTube video link here...\", lines=1)\n",
    "                submit_btn = gr.Button(\"‚ñ∂Ô∏è Process Video\")\n",
    "\n",
    "            with gr.Accordion(\"üìù Transcribed Text\", open=False):\n",
    "                transcript_output = gr.Textbox(label=\"Transcript\", lines=10, interactive=False)\n",
    "\n",
    "            with gr.Accordion(\"üß† Summary\", open=False):\n",
    "                summary_output = gr.Textbox(label=\"Summary\", lines=5, interactive=False)\n",
    "\n",
    "            hidden_text = gr.Textbox(visible=False)\n",
    "\n",
    "            def transcribe_and_summarize(youtube_url):\n",
    "                audio_path = download_audio_from_youtube(youtube_url)\n",
    "                transcribed_text = transcribe_with_whisper(audio_path)\n",
    "                documents = convert_to_documents([transcribed_text])\n",
    "                add_documents_to_vectorstore(documents)\n",
    "                summary = summarize_text(transcribed_text)\n",
    "                return transcribed_text, summary, transcribed_text\n",
    "\n",
    "            submit_btn.click(\n",
    "                transcribe_and_summarize,\n",
    "                inputs=youtube_url,\n",
    "                outputs=[transcript_output, summary_output, hidden_text]\n",
    "            )\n",
    "\n",
    "        with gr.TabItem(\"ü§ñ Ask the Chatbot\"):\n",
    "            chatbot_display = gr.Chatbot(label=\"üí¨ Chat with the Bot\", height=400)\n",
    "            with gr.Row():\n",
    "                user_question = gr.Textbox(placeholder=\"Type your message...\", show_label=False, lines=1)\n",
    "                submit_chat = gr.Button(\"üì§ Send\")\n",
    "\n",
    "            def answer_question_with_chatbot(user_input):\n",
    "                response = chat_with_bot(user_input)\n",
    "                chat_history.append((user_input, response))\n",
    "                return chat_history, \"\"\n",
    "\n",
    "            submit_chat.click(\n",
    "                answer_question_with_chatbot,\n",
    "                inputs=user_question,\n",
    "                outputs=[chatbot_display, user_question]\n",
    "            )\n",
    "            \n",
    "            \n",
    "\n",
    "interface.launch(share=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
